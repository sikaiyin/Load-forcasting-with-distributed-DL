{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar100\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, ZeroPadding2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.utils import print_summary, to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import Callback, LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Lambda\n",
    "from keras import backend as K\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 100\n",
    "NUM_CLASSES = 100\n",
    "EPOCHS = 1\n",
    "INIT_DROPOUT_RATE = 0.5\n",
    "MOMENTUM_RATE = 0.9\n",
    "INIT_LEARNING_RATE = 0.01\n",
    "L2_DECAY_RATE = 0.0005\n",
    "CROP_SIZE = 32\n",
    "num_labels = 100\n",
    "batch_size = 100\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_dims :  (50000, 32, 32, 3)\n",
      "x_test_dims :  (10000, 32, 32, 3)\n",
      "y_train_dims :  (50000, 1)\n",
      "y_test_dims :  (10000, 1)\n",
      "number of training examples available :  50000\n",
      "number of testing examples available :  10000\n"
     ]
    }
   ],
   "source": [
    "classes = 100\n",
    "#print(current_path)\n",
    "#model_name = 'cifar100.h5'\n",
    "(x_train, y_train) , (x_test, y_test) = cifar100.load_data()\n",
    "print('x_train_dims : ' , x_train.shape)\n",
    "print('x_test_dims : ', x_test.shape)\n",
    "print('y_train_dims : ', y_train.shape)\n",
    "print('y_test_dims : ', y_test.shape)\n",
    "\n",
    "print( 'number of training examples available : ', x_train.shape[0])\n",
    "print('number of testing examples available : ', x_test.shape[0])\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, classes)\n",
    "y_test = keras.utils.to_categorical(y_test, classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_dims :  (50000, 32, 32, 3)\n",
      "x_test_dims :  (10000, 32, 32, 3)\n",
      "y_train_dims :  (50000, 100)\n",
      "y_test_dims :  (10000, 100)\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print('x_train_dims : ' , x_train.shape)\n",
    "print('x_test_dims : ', x_test.shape)\n",
    "print('y_train_dims : ', y_train.shape)\n",
    "print('y_test_dims : ', y_test.shape)\n",
    "print(x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neg_hscore(x):\n",
    "    \"\"\"\n",
    "        negative hscore calculation\n",
    "        \"\"\"\n",
    "    f = x[0]\n",
    "    g = x[1]\n",
    "    f0 = f - K.mean(f, axis = 0)\n",
    "    g0 = g - K.mean(g, axis = 0)\n",
    "    corr = tf.reduce_mean(tf.reduce_sum(tf.multiply(f0, g0), 1))\n",
    "    cov_f = K.dot(K.transpose(f0), f0) / K.cast(K.shape(f0)[0] - 1, dtype = 'float32')\n",
    "    cov_g = K.dot(K.transpose(g0), g0) / K.cast(K.shape(g0)[0] - 1, dtype = 'float32')\n",
    "    return - corr + tf.trace(K.dot(cov_f, cov_g)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "  400/50000 [..............................] - ETA: 2:20:45 - loss: 12.0586"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2432675ed7f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m           validation_data=([x_test, y_test], np.zeros([y_test.shape[0], 1])))\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mmodel_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fdim = 100\n",
    "gdim = fdim\n",
    "\n",
    "\n",
    "input_x = Input(shape = x_train.shape[1:])\n",
    "zero1 = ZeroPadding2D(4, input_shape=x_train.shape[1:])(input_x)\n",
    "conv1 = Conv2D(384, kernel_size=(3, 3),\n",
    "               input_shape=x_train.shape[1:],\n",
    "               padding='same', kernel_regularizer=l2(0.01))(zero1)\n",
    "ac1 = Activation('elu')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2,2), padding='same')(ac1)\n",
    "f1 = Dropout(0.5)(pool1)\n",
    "\n",
    "conv2 = Conv2D(384, (1, 1), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(f1)\n",
    "conv3 = Conv2D(384, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(conv2)\n",
    "conv4 = Conv2D(640, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(conv3)\n",
    "conv5 = Conv2D(640, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(conv4)\n",
    "ac2 = Activation('elu')(conv5)\n",
    "pool2 = MaxPooling2D(pool_size=(2,2), padding='same')(ac2)\n",
    "f2 = Dropout(0.5)(pool2)\n",
    "\n",
    "\n",
    "conv6 = Conv2D(640, (3, 3), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(f2)\n",
    "conv7 = Conv2D(768, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(conv6)\n",
    "conv8 = Conv2D(768, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(conv7)\n",
    "conv9 = Conv2D(768, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(conv8)\n",
    "ac3 = Activation('elu')(conv9)\n",
    "pool3 = MaxPooling2D(pool_size=(2,2), padding='same')(ac3)\n",
    "f3 = Dropout(0.5)(pool3)\n",
    "\n",
    "conv10 = Conv2D(768, (1, 1), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(f3)\n",
    "conv11 = Conv2D(896, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(conv10)\n",
    "conv12 = Conv2D(896, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(conv11)\n",
    "ac4 = Activation('elu')(conv12)\n",
    "pool4 = MaxPooling2D(pool_size=(2,2), padding='same')(ac4)\n",
    "f4 = Dropout(0.5)(pool4)\n",
    "\n",
    "\n",
    "conv13 = Conv2D(896, (3, 3), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(f4)\n",
    "conv14 = Conv2D(1024, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(conv13)\n",
    "conv15 = Conv2D(1024, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(conv14)\n",
    "ac5 = Activation('elu')(conv15)\n",
    "pool5 = MaxPooling2D(pool_size=(2,2), padding='same')(ac5)\n",
    "f5 = Dropout(0.5)(pool5)\n",
    "\n",
    "conv16 = Conv2D(1024, (1, 1), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(f5)\n",
    "conv17 = Conv2D(1152, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(conv16)\n",
    "ac6 = Activation('elu')(conv17)\n",
    "pool6 = MaxPooling2D(pool_size=(2,2), padding='same')(ac6)\n",
    "f6 = Dropout(0.5)(pool6)\n",
    "\n",
    "conv18 = Conv2D(1152, (1, 1), padding='same', kernel_regularizer=l2(L2_DECAY_RATE))(f6)\n",
    "ac7 = Activation('elu')(conv18)\n",
    "pool7 = MaxPooling2D(pool_size=(2,2), padding='same')(ac7)\n",
    "f7 = Dropout(0.5)(pool7)\n",
    "\n",
    "f = Flatten()(f7)\n",
    "f = Dense(fdim)(f)\n",
    "\n",
    "input_y = Input(shape = (num_labels, ))\n",
    "g = Dense(gdim)(input_y)\n",
    "g = Dropout(0.5)(g)\n",
    "\n",
    "loss = Lambda(neg_hscore)([f, g])\n",
    "\n",
    "model = Model(inputs = [input_x, input_y], outputs = loss)\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay = 1e-6)\n",
    "\n",
    "model.compile(optimizer=opt, loss = lambda y_true,y_pred: y_pred)\n",
    "\n",
    "model.fit([x_train, y_train],\n",
    "          np.zeros([y_train.shape[0], 1]),\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data=([x_test, y_test], np.zeros([y_test.shape[0], 1])))\n",
    "\n",
    "model_f = Model(inputs = input_x, outputs = f)\n",
    "model_g = Model(inputs = input_y, outputs = g)\n",
    "\n",
    "f_test = model_f.predict(x_test)\n",
    "f_test0 = f_test - np.mean(f_test, axis = 0)\n",
    "g_val = model_g.predict(np.eye(100))\n",
    "py = np.mean(y_train, axis = 0)\n",
    "g_val0 = g_val - np.matmul(py, g_val)  # get zero-mean g(Y)\n",
    "# BUG fixed\n",
    "pygx = py * (1 + np.matmul(f_test0, g_val0.T))\n",
    "acc = np.mean(np.argmax(pygx, axis = 1) == np.argmax(y_test, axis = 1))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
